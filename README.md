# **Security_Data_Science**  
# üìå **Laboratorio #3 ‚Äì Detecci√≥n de Malware mediante Secuencias de Llamadas a API**  

## üìñ **Objetivos**  
- Implementar modelos de **Machine Learning (ML)** y **Deep Learning (DL)** para la detecci√≥n de malware basados en el an√°lisis din√°mico de llamadas a API.  
- Evaluar y comparar ambos enfoques para determinar cu√°l ofrece mejores resultados en t√©rminos de precisi√≥n y capacidad de detecci√≥n.  

## üìÇ **Contenido del Proyecto**  
El laboratorio est√° desarrollado en un **Jupyter Notebook (`.ipynb`)** e incluye los siguientes pasos:  

### **1. Carga y preprocesamiento de datos**  
   - Lectura del dataset con las secuencias de llamadas a API.  
   - Limpieza y transformaci√≥n de los datos.  
   - Divisi√≥n en conjuntos de entrenamiento y prueba.  

### **2. Implementaci√≥n de Modelos**  
   - **Modelo 1 (Machine Learning con Naive Bayes)**  
     - Representaci√≥n de las llamadas a API mediante **TF-IDF**.  
     - Entrenamiento con **Naive Bayes Multinomial**.  
     - Evaluaci√≥n con validaci√≥n cruzada (k=10).  

   - **Modelo 2 (Deep Learning con Redes Neuronales)**  
     - Generaci√≥n de **embeddings** a partir de modelos NLP (`SentenceTransformers`).  
     - Implementaci√≥n de una **Red Neuronal Artificial (ANN)** con capas densas y dropout.  
     - Entrenamiento y ajuste del modelo con optimizador **Adam**.  

### **3. Evaluaci√≥n de Modelos**  
   - C√°lculo de m√©tricas clave para cada modelo:  
     - **Precisi√≥n (Accuracy)**  
     - **Precisi√≥n y Recall (Precision & Recall)**  
     - **Curva ROC-AUC**  
   - Comparaci√≥n de resultados y an√°lisis de rendimiento.  

### **4. Comparaci√≥n y An√°lisis de Impacto**  
   - Evaluaci√≥n de la capacidad de cada modelo para detectar malware.  
   - Discusi√≥n sobre la importancia de capturar patrones en las llamadas a API.  
   - An√°lisis de falsos positivos y falsos negativos.  

## üìä **Modelos Utilizados**  

- **Modelo 1: Naive Bayes con TF-IDF**  
  - Utiliza **frecuencia de t√©rminos (TF-IDF)** para representar las llamadas a API.  
  - Se basa en **Naive Bayes Multinomial**, un algoritmo probabil√≠stico eficiente para clasificaci√≥n de texto.  
  - **Precisi√≥n obtenida: 82.44%**.  
  - **√Årea bajo la curva ROC (AUC): 0.95**.  

- **Modelo 2: Redes Neuronales con Embeddings**  
  - Emplea **embeddings generados con NLP (SentenceTransformers)** para capturar mejor las relaciones sem√°nticas entre las llamadas a API.  
  - Se entrena una **Red Neuronal Artificial (ANN)** con m√∫ltiples capas densas y dropout.  
  - **Precisi√≥n obtenida: 94.72%**.  
  - **√Årea bajo la curva ROC (AUC): 0.97**.  

## üìå **Requisitos**  
Para ejecutar el laboratorio, aseg√∫rate de tener instaladas las siguientes bibliotecas de Python:  

```python
pip install -r requirements.txt
```

# üöÄ C√≥mo ejecutar el laboratorio
	1.	Descarga el archivo Lab3.ipynb.
	2.	Aseg√∫rate de tener instaladas las bibliotecas necesarias.
	3.	Abre el Jupyter Notebook y ejecuta las celdas secuencialmente.
	4.	Analiza los resultados y compara los modelos.

# üèÜ Resultados y Conclusiones

Despu√©s de comparar los modelos:
	‚Ä¢	El Modelo 2 (Redes Neuronales) super√≥ al Modelo 1 en todas las m√©tricas, con una precisi√≥n del 94.72% frente al 82.44% del Modelo 1.
	‚Ä¢	El Modelo 2 tambi√©n logr√≥ una mejor capacidad de discriminaci√≥n entre malware y benignos (AUC=0.97 vs. AUC=0.95).
	‚Ä¢	Sin embargo, el Modelo 1 es m√°s r√°pido y computacionalmente eficiente, lo que puede ser √∫til en escenarios donde los recursos son limitados.

El an√°lisis mostr√≥ que el uso de embeddings y redes neuronales permite mejorar significativamente la detecci√≥n de malware, aline√°ndose con lo descrito en el art√≠culo ‚ÄúAutomated Behaviour-Based Malware Detection 
Framework Based on NLP and Deep Learning Techniques‚Äù. No obstante, si se requiere una soluci√≥n m√°s ligera y r√°pida, el Modelo 1 sigue siendo una alternativa viable.

---

‚úâÔ∏è **Autores:** *Marco Ram√≠rez y Rebecca Smith*  
üìÖ **√öltima actualizaci√≥n:** *02-03-2025*  

---
